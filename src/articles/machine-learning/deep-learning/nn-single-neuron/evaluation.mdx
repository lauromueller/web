---
title: 'Programming a single neuron - Part 4: Evaluation and further discussions'
date: '2020-01-10'
field: machine-learning
area: deep-learning
slug: nn-single-neuron-evaluation
series: nn-single-neuron
category: no category
draft: False
tags: ['deep learning', 'neural networks']
---

# 6. Evaluating the model

## 6.1 How confident is our classifier?

Remember our discussion in section 4.3.1 about how we transform the real-valued neuron's output into the actual binary classification output by checking whether the value of the sigmoid function is larger than $0.5$ or not? This means that the values $0.51$ and $0.99$ will lead to the same classification, although they are clearly different in practice. While the former can be interpreted as a very "uncertain" classification (it lies almost on the border dividing negative and positive instances), the latter represents a very "certain" output. We can go a step further and model this concept in a mathematical function given by the distance between the sigmoid output and $0.5$, and then observe how this evolves over time and how this differs from model to model. More formally:

$$
confidence = | \sigma (wX + b) - 0.5 |
$$

Where $confidence \in [0, 0.5]$ tells us how certain our model is about the classification (either positive or negative).

# 7. Discussions

# 7.1 Why do we need negative examples in the dataset?

# 7.2 Do we need random initialization of weights?
